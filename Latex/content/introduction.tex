\chapter{Introduction}\label{ch:introduction}

Reverse engineering is a critical process in software security, enabling analysts to understand, debug, and modify software without access to its source code~\cite{Paper:chikofsky1990reverse}.
Decompilation tools like \texttt{Ghidra} and \texttt{Hex-Rays} have long been the backbone of this process, translating binary executables back into high-level code~\cite{Paper:eagle2011idapro, site:ghidra2019}.
However, the output from these tools often suffers from issues such as poor readability, non-idiomatic constructs, and a lack of meaningful variable names, 
which can significantly hinder the analyst's ability to comprehend and work with the decompiled code.
 
The advent of \ac{LLM} has opened new avenues for enhancing reverse engineering workflows. \ac{LLM} have demonstrated remarkable capabilities in understanding and generating code, making them promising candidates for improving 
the quality of decompiled output. Recent research has explored using \ac{LLM} to refine decompiler output, generate comments, and even act as judges 
to evaluate code quality. However, much of this work has focused on either generative refinement or broad benchmarking of decompilers, 
often relying on proprietary models and tools~\cite{Paper:Tan_2024, Paper:Hu2024DeGPTOD}.
In this thesis, we take a different approach by leveraging \ac{LLM} to evaluate the ``humanness'' of decompiled code using intrinsic model 
metrics like \texttt{perplexity}~\cite{Paper:hindle2012naturalness}. We investigate how well local \ac{LLM} can distinguish between different versions of the same codebase, 
such as \texttt{pull requests}, without modifying the code itself. This fine-grained analysis is crucial for assessing incremental changes in code 
quality and readability, which is often more relevant in real-world reverse engineering tasks than wholesale comparisons of different decompilers.
Our work also addresses the practical constraints of reverse engineering, such as privacy and cost, by exploring the feasibility of running these 
evaluations on local hardware, rather than relying on cloud-based \texttt{\ac{API}s}. This makes our approach more accessible and applicable in security-sensitive contexts 
where data privacy is paramount~\cite{Paper:staab2024beyond, Paper:carlini2021extracting}.

%%TODO: results summary
\dots