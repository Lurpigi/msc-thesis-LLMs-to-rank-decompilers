\documentclass{meta/masterthesis}
% masterthesis for Computer Science
% masterthesis_ceng for Computer Engineering
% use the [nocoverpage] option to speed up compilation by skipping the cover page

% the configuration is in the preamble.tex file, read it and modify it to change
% the document appearance and included packages
\input{meta/preamble}

% by default, we use the biblatex package to manage the bibliography
% if you prefer to use bibtex, comment the following line and uncomment the
% relevant lines at the end of the document
\addbibresource{meta/bib.bib}

\input{meta/acronyms}

\begin{document}

\title{Using LLMs to Rank Decompiled Code Variants}

\author{Luigi Timossi}

% important for when you'll submit your thesis: your advisor(s) are "relatore", and the examiner is "correlatore".

\advisor{Matteo Dell'Amico, Giovanni Lagorio}

\examiner{Marina Ribaudo}

\maketitle

\begin{abstract}
Reverse engineering relies heavily on decompilers to translate compiled binaries back into readable high-level code. However, assessing the quality and ``human-likeness'' of decompiled output remains a highly subjective and challenging task. Traditional metrics fall short of capturing readability, idiomatic structures, and semantic clarity. This thesis investigates the use of \acp{LLM} to automatically evaluate and rank decompiled code variants. We compare two main approaches: using intrinsic statistical metrics, specifically perplexity, and employing \acp{LLM} as qualitative judges (LLM-as-a-Judge). We evaluate two open-weight models, \emph{qwen-3} and \emph{deepseek-r1}, on a dataset of real-world C projects decompiled with Ghidra (comparing different commits and Pull Requests) and other decompilers via Dogbolt (Binary Ninja, Hex-Rays).

Our findings reveal that perplexity is a poor proxy for human-likeness, as human-authored code naturally exhibits higher entropy and structural variance compared to the rigid, repetitive boilerplate generated by decompilers. Conversely, the LLM-as-a-Judge approach shows significant promise: \emph{deepseek-r1} achieved an alignment of $\sim$74\% with human developers' judgments. However, we also identify critical vulnerabilities in \acp{LLM}, such as lexical bias, verbosity, and analytical hallucinations when faced with minor stylistic differences. We demonstrate that abstracting the code into an \ac{AST} effectively mitigates some of these lexical biases. Ultimately, this work establishes a robust baseline for automated decompiler evaluation and highlights both the potential and the limitations of using \ac{LLM} in reverse engineering workflows.
\end{abstract}

\tableofcontents

\include{content/introduction}

\include{content/related}

\include{content/background}

\include{content/method}

\include{content/results}

\include{content/conclusion}

% Bibliography using biber; comment this and uncomment the following lines to use bibtex instead
\printbibliography
% \bibliographystyle{alphaurl}
% \bibliography{bib}

\include{content/appendix}

\end{document}

